#!/usr/bin/env python3
"""
GLM (æ™ºè°±) API Client for WeeklyAI

ç”¨äºä¸­å›½åŒº AI äº§å“å‘ç°ï¼Œä½¿ç”¨æ™ºè°± GLM è”ç½‘æœç´¢ APIã€‚

API æ–‡æ¡£: https://open.bigmodel.cn/dev/api

æ”¯æŒåŠŸèƒ½ï¼š
1. Web Search API: è”ç½‘æœç´¢ï¼ˆsearch_pro / search_pro_sogouï¼‰
2. Chat API: GLM-4 æ¨¡å‹åˆ†æ
3. ç»„åˆæ–¹æ³•: æœç´¢ + åˆ†æä¸€ä½“åŒ–

Usage:
    from utils.glm_client import GLMClient

    client = GLMClient(api_key="your-key")

    # æ–¹å¼1: çº¯æœç´¢
    results = client.search("AIèèµ„ 2026")

    # æ–¹å¼2: æœç´¢ + åˆ†æ
    products = client.search_and_extract(
        query="AIåˆ›ä¸šå…¬å¸ èèµ„ 2026",
        analysis_prompt="Extract AI products...",
        region="cn"
    )
"""

import os
import json
import time
import re
import requests
from typing import Optional, Union
from dataclasses import dataclass, field

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å…¨å±€é…ç½®
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ZHIPU_API_KEY = os.environ.get('ZHIPU_API_KEY', '')
GLM_MODEL = os.environ.get('GLM_MODEL', 'glm-4.7')  # æœ€æ–°: glm-4.7 (200K context, 128K output)
GLM_SEARCH_ENGINE = os.environ.get('GLM_SEARCH_ENGINE', 'search_pro')  # search_pro / search_pro_sogou / search_pro_quark
API_RATE_LIMIT_DELAY = float(os.environ.get('API_RATE_LIMIT_DELAY', '2'))
API_MAX_RETRIES = int(os.environ.get('API_MAX_RETRIES', '3'))
API_RETRY_BACKOFF = float(os.environ.get('API_RETRY_BACKOFF', '2'))
GLM_THINKING_TYPE = os.environ.get('GLM_THINKING_TYPE', 'disabled')  # enabled/disabled
GLM_CLEAR_THINKING = os.environ.get('GLM_CLEAR_THINKING', 'true').lower() == 'true'
USE_GLM_FOR_CN = os.environ.get('USE_GLM_FOR_CN', 'true').lower() == 'true'

# ç‹¬ç«‹ Web Search API ç«¯ç‚¹
GLM_WEB_SEARCH_URL = "https://open.bigmodel.cn/api/paas/v4/web_search"

# GLM-4.7 é»˜è®¤é‡‡æ ·å‚æ•°
GLM_DEFAULT_TEMPERATURE = 1.0  # GLM-4.7 é»˜è®¤å€¼
GLM_DEFAULT_TOP_P = 0.95       # GLM-4.7 é»˜è®¤å€¼

# æœç´¢å¼•æ“é…ç½®
SEARCH_ENGINES = {
    "search_pro": {
        "name": "æ™ºè°±é«˜é˜¶æœç´¢",
        "price": "Â¥0.03/æ¬¡",
        "description": "æ™ºè°±è‡ªç ”é«˜é˜¶ç‰ˆï¼Œé€‚åˆé€šç”¨æœç´¢"
    },
    "search_pro_sogou": {
        "name": "æœç‹—é«˜é˜¶æœç´¢",
        "price": "Â¥0.05/æ¬¡",
        "description": "è…¾è®¯ç”Ÿæ€+çŸ¥ä¹ï¼Œé€‚åˆä¸­æ–‡å†…å®¹æ·±åº¦æœç´¢"
    },
    "search_pro_quark": {
        "name": "å¤¸å…‹é«˜é˜¶æœç´¢",
        "price": "Â¥0.05/æ¬¡",
        "description": "å¤¸å…‹æœç´¢å¢å¼ºï¼Œé€‚åˆä¸­æ–‡ç«™ç‚¹å¬å›"
    },
    "search_std": {
        "name": "æ ‡å‡†æœç´¢",
        "price": "Â¥0.01/æ¬¡",
        "description": "åŸºç¡€æœç´¢ï¼Œé€‚åˆç®€å•æŸ¥è¯¢"
    }
}

# ä¸­å›½æƒå¨ AI åª’ä½“åŸŸåï¼ˆç”¨äºè¿‡æ»¤ä¼˜è´¨ç»“æœï¼‰
CN_TRUSTED_DOMAINS = [
    "36kr.com",
    "jiqizhixin.com",
    "itjuzi.com",
    "tmtpost.com",
    "qbitai.com",
    "leiphone.com",
    "thepaper.cn",
    "geekpark.net",
]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ•°æ®ç±»ï¼ˆä¸ Perplexity å®¢æˆ·ç«¯ä¿æŒä¸€è‡´ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class SearchResult:
    """æœç´¢ç»“æœ"""
    title: str
    url: str
    snippet: str
    date: Optional[str] = None
    source: Optional[str] = None

    def to_dict(self) -> dict:
        return {
            "title": self.title,
            "url": self.url,
            "content": self.snippet,
            "date": self.date,
            "source": self.source
        }

    def format_for_prompt(self) -> str:
        """æ ¼å¼åŒ–ä¸º Prompt æ–‡æœ¬"""
        lines = [f"### {self.title}"]
        lines.append(f"Source URL: {self.url}")
        if self.date:
            lines.append(f"Date: {self.date}")
        if self.source:
            lines.append(f"Source: {self.source}")
        lines.append(f"Content: {self.snippet}")
        return "\n".join(lines)


@dataclass
class ExtractionResult:
    """æå–ç»“æœ"""
    products: list = field(default_factory=list)
    sources: list = field(default_factory=list)
    raw_response: str = ""
    search_count: int = 0
    extract_count: int = 0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GLM å®¢æˆ·ç«¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class GLMClient:
    """
    æ™ºè°± GLM API å®¢æˆ·ç«¯

    é»˜è®¤ä½¿ç”¨ GLM-4.7 æ¨¡å‹ï¼Œç‰¹æ€§ï¼š
    - æœ€å¤§ä¸Šä¸‹æ–‡ 200Kï¼Œæœ€å¤§è¾“å‡º 128K
    - æ”¯æŒæ·±åº¦æ€è€ƒ (thinking)
    - æ”¯æŒæµå¼å·¥å…·è°ƒç”¨

    æ”¯æŒï¼š
    - Web Search Tool: è”ç½‘æœç´¢
    - Chat Completions API: GLM æ¨¡å‹åˆ†æ
    - ç»„åˆæ–¹æ³•: æœç´¢ + åˆ†æä¸€ä½“åŒ–
    """

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or ZHIPU_API_KEY
        self.model = GLM_MODEL
        self.search_engine = GLM_SEARCH_ENGINE
        self._client = None
        self._search_session = None

        if self.api_key:
            # Setup requests.Session for direct Web Search API
            self._search_session = requests.Session()
            self._search_session.headers.update({
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
            })
            # Setup ZhipuAI SDK for analyze() (chat completions)
            try:
                from zhipuai import ZhipuAI
                self._client = ZhipuAI(api_key=self.api_key)
            except ImportError:
                print("âš ï¸ zhipuai SDK not installed. Run: pip install zhipuai")
        else:
            print("âš ï¸ ZHIPU_API_KEY not set")

    def is_available(self) -> bool:
        """æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦å¯ç”¨"""
        return self._search_session is not None or self._client is not None

    def _rate_limit(self):
        """API é™æµ"""
        time.sleep(API_RATE_LIMIT_DELAY)

    def _is_rate_limited(self, error: Exception) -> bool:
        """åˆ¤æ–­æ˜¯å¦è§¦å‘é™æµ"""
        msg = str(error)
        return ("Error code: 429" in msg) or ("1302" in msg) or ("å¹¶å‘æ•°è¿‡é«˜" in msg)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Web Search (ç‹¬ç«‹ Web Search API)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def search(
        self,
        query: str,
        max_results: int = 10,
        search_engine: Optional[str] = None,
    ) -> list[SearchResult]:
        """
        ä½¿ç”¨æ™ºè°±ç‹¬ç«‹ Web Search API æœç´¢

        ç›´æ¥è°ƒç”¨ POST /paas/v4/web_searchï¼Œè¿”å›ç»“æ„åŒ–æœç´¢ç»“æœï¼ˆçœŸå® URLï¼‰ã€‚
        ä¸ç»è¿‡ GLM æ¨¡å‹ï¼Œé¿å…å¹»è§‰ URLã€‚

        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœŸæœ›ç»“æœæ•°é‡ (æœ€å¤§ 50)
            search_engine: æœç´¢å¼•æ“ (search_pro/search_pro_sogou/search_pro_quark/search_std)

        Returns:
            SearchResult åˆ—è¡¨
        """
        if not self._search_session:
            return []

        engine = search_engine or self.search_engine
        print(f"  ğŸ” GLM Web Search API ({engine}): {query[:50]}...")

        payload = {
            "search_query": query,
            "search_engine": engine,
            "search_intent": False,
            "count": min(max_results, 50),
            "content_size": "medium",
            "search_recency_filter": "oneWeek",
        }

        last_error: Optional[Exception] = None
        for attempt in range(1, API_MAX_RETRIES + 1):
            try:
                resp = self._search_session.post(
                    GLM_WEB_SEARCH_URL, json=payload, timeout=30
                )
                resp.raise_for_status()
                data = resp.json()

                results = []
                for item in data.get("search_result", []):
                    url = (item.get("link") or "").strip()
                    title = (item.get("title") or "").strip()
                    if not url or not title:
                        continue
                    results.append(SearchResult(
                        title=title,
                        url=url,
                        snippet=(item.get("content") or "").strip(),
                        date=item.get("publish_date"),
                        source=item.get("media"),
                    ))

                print(f"  âœ… Found {len(results)} results")
                return results[:max_results]

            except requests.exceptions.HTTPError as e:
                last_error = e
                status = e.response.status_code if e.response is not None else 0
                if status == 429 and attempt < API_MAX_RETRIES:
                    wait = API_RATE_LIMIT_DELAY * (API_RETRY_BACKOFF ** (attempt - 1))
                    print(f"  â³ GLM rate limited, retrying in {wait:.1f}s "
                          f"(attempt {attempt}/{API_MAX_RETRIES})")
                    time.sleep(wait)
                    continue
                print(f"  âŒ GLM Web Search HTTP Error ({status}): {e}")
                break
            except Exception as e:
                last_error = e
                if self._is_rate_limited(e) and attempt < API_MAX_RETRIES:
                    wait = API_RATE_LIMIT_DELAY * (API_RETRY_BACKOFF ** (attempt - 1))
                    print(f"  â³ GLM rate limited, retrying in {wait:.1f}s "
                          f"(attempt {attempt}/{API_MAX_RETRIES})")
                    time.sleep(wait)
                    continue
                print(f"  âŒ GLM Web Search Error: {e}")
                break
            finally:
                self._rate_limit()

        if last_error and (
            self._is_rate_limited(last_error)
            or (isinstance(last_error, requests.exceptions.HTTPError)
                and last_error.response is not None
                and last_error.response.status_code == 429)
        ):
            print("  âš ï¸ GLM search failed due to rate limit; consider reducing traffic or "
                  "raising API concurrency limits.")
        return []

    def search_by_region(
        self,
        query: str,
        region: str = "cn",
        max_results: int = 10,
        **kwargs
    ) -> list[SearchResult]:
        """
        æŒ‰åœ°åŒºæœç´¢ï¼ˆGLM ä¸»è¦æœåŠ¡ä¸­å›½åŒºï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢
            region: åœ°åŒºä»£ç  (cn)
            max_results: ç»“æœæ•°é‡
        """
        # GLM ä¸»è¦ç”¨äºä¸­å›½åŒºæœç´¢ï¼Œå…¶ä»–åœ°åŒºåº”ä½¿ç”¨ Perplexity
        if region != "cn":
            print(f"  âš ï¸ GLM is optimized for CN region, got: {region}")

        return self.search(query, max_results=max_results, **kwargs)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Chat Completions API (åˆ†æå†…å®¹)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def analyze(
        self,
        prompt: str,
        model: Optional[str] = None,
        temperature: float = 0.3,
        max_tokens: int = 4096,
        top_p: Optional[float] = None
    ) -> Union[dict, list, str]:
        """
        ä½¿ç”¨ GLM æ¨¡å‹åˆ†æå†…å®¹

        GLM-4.7 é‡‡æ ·å‚æ•°è¯´æ˜ï¼š
        - temperature: é»˜è®¤ 1.0ï¼Œæ§åˆ¶éšæœºæ€§ï¼ˆæ›´é«˜æ›´å‘æ•£ï¼Œæ›´ä½æ›´ç¨³å®šï¼‰
        - top_p: é»˜è®¤ 0.95ï¼Œæ§åˆ¶æ ¸é‡‡æ ·ï¼ˆæ›´é«˜æ‰©å¤§å€™é€‰é›†ï¼Œæ›´ä½æ”¶æ•›å€™é€‰é›†ï¼‰
        - å»ºè®®åªè°ƒæ•´å…¶ä¸­ä¸€ä¸ªå‚æ•°ï¼Œä¸è¦åŒæ—¶è°ƒæ•´

        Args:
            prompt: å®Œæ•´ prompt (åŒ…å«æœç´¢ç»“æœå’ŒæŒ‡ä»¤)
            model: æ¨¡å‹ (glm-4.7/glm-4-flash)
            temperature: æ¸©åº¦ (0-2ï¼Œæ¨è 0.3 ä»¥è·å¾—ç¨³å®šè¾“å‡ºç”¨äºæå–ä»»åŠ¡)
            max_tokens: æœ€å¤§ token (GLM-4.7 æ”¯æŒæœ€å¤§ 128K)
            top_p: æ ¸é‡‡æ ·å‚æ•° (å¯é€‰ï¼Œä¸ temperature äºŒé€‰ä¸€)

        Returns:
            è§£æåçš„ JSON æˆ–åŸå§‹æ–‡æœ¬
        """
        if not self._client:
            return {}

        model = model or self.model

        # æ„å»ºè¯·æ±‚å‚æ•°
        request_params = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": max_tokens,
            "thinking": {
                "type": GLM_THINKING_TYPE,
                "clear_thinking": GLM_CLEAR_THINKING
            }
        }

        # ä½¿ç”¨ temperature æˆ– top_pï¼ˆå»ºè®®åªç”¨ä¸€ä¸ªï¼‰
        if top_p is not None:
            request_params["top_p"] = top_p
        else:
            request_params["temperature"] = temperature

        last_error: Optional[Exception] = None
        for attempt in range(1, API_MAX_RETRIES + 1):
            try:
                response = self._client.chat.completions.create(**request_params)

                result_text = response.choices[0].message.content or ""
                return self._extract_json(result_text)

            except Exception as e:
                last_error = e
                if self._is_rate_limited(e) and attempt < API_MAX_RETRIES:
                    wait = API_RATE_LIMIT_DELAY * (API_RETRY_BACKOFF ** (attempt - 1))
                    print(f"  â³ GLM rate limited, retrying in {wait:.1f}s "
                          f"(attempt {attempt}/{API_MAX_RETRIES})")
                    time.sleep(wait)
                    continue
                print(f"  âŒ GLM Analyze Error: {e}")
                break
            finally:
                self._rate_limit()

        if last_error and self._is_rate_limited(last_error):
            print("  âš ï¸ GLM analysis failed due to rate limit; consider reducing traffic or "
                  "raising API concurrency limits.")
        return {}

    def _extract_json(self, text: str) -> Union[dict, list, str]:
        """ä»æ–‡æœ¬ä¸­æå– JSON.

        Returns parsed JSON (list or dict) on success.
        Returns [] on parse failure so callers never receive raw text
        that masquerades as valid data.
        """
        if not text:
            return []

        # å°è¯• ```json ... ``` å—
        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', text)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass

        # å°è¯•ç›´æ¥è§£æ
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            pass

        # å°è¯•æ‰¾åˆ° JSON æ•°ç»„
        array_match = re.search(r'\[\s*\{[\s\S]*\}\s*\]', text)
        if array_match:
            try:
                return json.loads(array_match.group())
            except json.JSONDecodeError:
                pass

        # å°è¯•æ‰¾åˆ° JSON å¯¹è±¡
        object_match = re.search(r'\{\s*"[\s\S]*\}', text)
        if object_match:
            try:
                return json.loads(object_match.group())
            except json.JSONDecodeError:
                pass

        # All parsing attempts failed â€” log and return empty list
        snippet = text[:200].replace('\n', ' ')
        print(f"  âš  _extract_json: could not parse response (first 200 chars): {snippet}")
        return []

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ç»„åˆæ–¹æ³•ï¼šæœç´¢ + åˆ†æ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def search_and_extract(
        self,
        query: str,
        analysis_prompt: str,
        region: str = "cn",
        max_results: int = 10,
        **search_kwargs
    ) -> ExtractionResult:
        """
        æœç´¢å¹¶æå–äº§å“ä¿¡æ¯ï¼ˆæ¨èæ–¹æ³•ï¼‰

        å·¥ä½œæµç¨‹:
        1. Web Search è·å–æœç´¢ç»“æœ
        2. æ ¼å¼åŒ–æœç´¢ç»“æœ
        3. GLM åˆ†æå¹¶æå–äº§å“

        Args:
            query: æœç´¢æŸ¥è¯¢
            analysis_prompt: åˆ†æ Promptï¼Œéœ€åŒ…å« {search_results} å ä½ç¬¦
            region: åœ°åŒºä»£ç  (cn)
            max_results: æœç´¢ç»“æœæ•°é‡

        Returns:
            ExtractionResult åŒ…å«äº§å“åˆ—è¡¨å’Œæ¥æº
        """
        result = ExtractionResult()

        # Step 1: æœç´¢
        search_results = self.search_by_region(query, region, max_results, **search_kwargs)
        result.search_count = len(search_results)
        result.sources = [r.url for r in search_results]

        if not search_results:
            return result

        # Step 2: æ ¼å¼åŒ–æœç´¢ç»“æœ
        formatted_results = "\n\n".join([r.format_for_prompt() for r in search_results])

        # Step 3: æ„å»º prompt å¹¶åˆ†æ
        full_prompt = analysis_prompt.replace("{search_results}", formatted_results)

        print(f"    ğŸ“Š Analyzing with GLM ({self.model})...")
        analysis = self.analyze(full_prompt)

        if isinstance(analysis, list):
            result.products = analysis
            result.extract_count = len(analysis)
        elif isinstance(analysis, dict):
            result.products = analysis.get("products", [analysis])
            result.extract_count = len(result.products)
        else:
            result.raw_response = str(analysis)

        print(f"    âœ… Extracted {result.extract_count} products")
        return result

    def format_results_for_prompt(self, results: list[SearchResult]) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœä¸º Prompt æ–‡æœ¬"""
        return "\n\n".join([r.format_for_prompt() for r in results])

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ä¾¿æ·æ–¹æ³•
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def get_status(self) -> dict:
        """è·å–å®¢æˆ·ç«¯çŠ¶æ€"""
        return {
            "available": self.is_available(),
            "api_key_set": bool(self.api_key),
            "model": self.model,
            "search_engine": self.search_engine,
            "search_mode": "direct_api",
            "search_engine_info": SEARCH_ENGINES.get(self.search_engine, {}),
            "thinking": {
                "type": GLM_THINKING_TYPE,
                "clear_thinking": GLM_CLEAR_THINKING
            }
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¾¿æ·å‡½æ•°ï¼ˆä¸ Perplexity å®¢æˆ·ç«¯æ¥å£ä¸€è‡´ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_default_client: Optional[GLMClient] = None


def get_client() -> GLMClient:
    """è·å–é»˜è®¤å®¢æˆ·ç«¯ï¼ˆå•ä¾‹ï¼‰"""
    global _default_client
    if _default_client is None:
        _default_client = GLMClient()
    return _default_client


def glm_search(query: str, max_results: int = 10, region: str = "cn", **kwargs) -> list[dict]:
    """
    å¿«é€Ÿæœç´¢

    Returns:
        [{"title": "", "url": "", "content": ""}, ...]
    """
    client = get_client()
    results = client.search_by_region(query, region, max_results, **kwargs)
    return [r.to_dict() for r in results]


def glm_analyze(prompt: str, **kwargs) -> Union[dict, list]:
    """å¿«é€Ÿåˆ†æ"""
    client = get_client()
    return client.analyze(prompt, **kwargs)


def is_glm_available() -> bool:
    """æ£€æŸ¥ GLM æ˜¯å¦å¯ç”¨"""
    return bool(ZHIPU_API_KEY) and USE_GLM_FOR_CN


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æµ‹è¯•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_client():
    """æµ‹è¯•å®¢æˆ·ç«¯"""
    print("\n" + "="*60)
    print("  ğŸ§ª Testing GLM Client (æ™ºè°±)")
    print("="*60)

    client = GLMClient()
    print(f"\n  Status: {client.get_status()}")

    if not client.is_available():
        print("\n  âŒ API key not set or SDK not installed.")
        print("  Set ZHIPU_API_KEY env var and run: pip install zhipuai")
        return False

    # Test 1: åŸºç¡€æœç´¢
    print("\n  ğŸ“ Test 1: Basic Search (ä¸­å›½ AI èèµ„)")
    results = client.search("AIåˆ›ä¸šå…¬å¸ èèµ„ 2026", max_results=3)
    if results:
        for i, r in enumerate(results, 1):
            print(f"    {i}. {r.title[:50]}...")
            print(f"       URL: {r.url}")
            print(f"       Date: {r.date}")
    else:
        print("    âš ï¸ No results (may need to check API)")

    # Test 2: åˆ†æ
    print("\n  ğŸ“ Test 2: GLM Analysis")
    test_prompt = """åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œæå–å…¬å¸åç§°å’Œç½‘ç«™ï¼š

### ç¤ºä¾‹æ–°é—»
æŸAIåˆ›ä¸šå…¬å¸å®ŒæˆAè½®èèµ„ï¼Œé‡‘é¢5000ä¸‡ç¾å…ƒï¼Œå®˜ç½‘ https://example.com

è¿”å› JSON æ ¼å¼: {"name": "...", "website": "..."}"""

    analysis = client.analyze(test_prompt, temperature=0.1)
    print(f"    Result: {analysis}")

    print("\n  âœ… GLM test completed!")
    return True


if __name__ == "__main__":
    test_client()
