"""
äº§å“æ•°æ®ä»“åº“ - è´Ÿè´£æ•°æ®åŠ è½½ã€æ–‡ä»¶I/Oå’Œç¼“å­˜ç®¡ç†
"""

import os
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional

# Sorting helpers for merge decisions
from . import product_sorting as sorting
from .env_utils import sanitize_env_value

# MongoDB support
try:
    from pymongo import MongoClient
    HAS_MONGO = True
except ImportError:
    HAS_MONGO = False

# å¯¼å…¥é…ç½®
from config import Config

# çˆ¬è™«æ•°æ®æ–‡ä»¶è·¯å¾„ (æ”¯æŒç¯å¢ƒå˜é‡é…ç½®ï¼ŒDocker éƒ¨ç½²æ—¶ä½¿ç”¨ /data)
CRAWLER_DATA_DIR = Config.DATA_PATH if os.path.exists(Config.DATA_PATH) else os.path.join(
    os.path.dirname(__file__),
    '..', '..', '..', 'crawler', 'data'
)
PRODUCTS_FEATURED_FILE = os.path.join(CRAWLER_DATA_DIR, 'products_featured.json')
BLOGS_NEWS_FILE = os.path.join(CRAWLER_DATA_DIR, 'blogs_news.json')
CRAWLER_DATA_FILE = os.path.join(CRAWLER_DATA_DIR, 'products_latest.json')
LAST_UPDATED_FILE = os.path.join(CRAWLER_DATA_DIR, 'last_updated.json')
DARK_HORSES_DIR = os.path.join(CRAWLER_DATA_DIR, 'dark_horses')

# MongoDB connection
_mongo_client = None
_mongo_db = None
_mongo_fail_until = None


def _get_env_int(name: str, default: int, minimum: int = 0) -> int:
    """Read an integer environment variable with clamped fallback."""
    raw = os.getenv(name, "").strip()
    if not raw:
        return default
    try:
        return max(minimum, int(raw))
    except ValueError:
        return default


MONGO_SERVER_SELECTION_TIMEOUT_MS = _get_env_int("MONGO_SERVER_SELECTION_TIMEOUT_MS", 800, minimum=100)
MONGO_FAILURE_COOLDOWN_SECONDS = _get_env_int("MONGO_FAILURE_COOLDOWN_SECONDS", 60, minimum=0)
BLOG_CACHE_SECONDS = _get_env_int("BLOG_CACHE_SECONDS", 60, minimum=1)


def _mongo_uri_configured() -> bool:
    """Whether MONGO_URI is explicitly configured."""
    return bool(sanitize_env_value(os.getenv('MONGO_URI', '')))


def get_mongo_db():
    """Get MongoDB connection (lazy initialization)."""
    global _mongo_client, _mongo_db, _mongo_fail_until
    if not HAS_MONGO:
        return None
    if not _mongo_uri_configured():
        return None
    if _mongo_db is not None:
        return _mongo_db
    if _mongo_fail_until and datetime.now() < _mongo_fail_until:
        return None
    try:
        mongo_uri = sanitize_env_value(os.environ.get('MONGO_URI', ''))
        if not mongo_uri:
            return None
        _mongo_client = MongoClient(mongo_uri, serverSelectionTimeoutMS=MONGO_SERVER_SELECTION_TIMEOUT_MS)
        _mongo_client.admin.command('ping')
        _mongo_db = _mongo_client.get_database()
        _mongo_fail_until = None
        print("  âœ“ Backend connected to MongoDB")
        return _mongo_db
    except Exception as e:
        if _mongo_client is not None:
            try:
                _mongo_client.close()
            except Exception:
                pass
            _mongo_client = None
        _mongo_db = None
        _mongo_fail_until = datetime.now() + timedelta(seconds=MONGO_FAILURE_COOLDOWN_SECONDS)
        print(f"  âš  MongoDB connection failed: {e}, using JSON files")
        return None


# ç¤ºä¾‹æ•°æ®ï¼ˆå½“æ²¡æœ‰çˆ¬è™«æ•°æ®æ—¶ä½¿ç”¨ï¼‰- åªåŒ…å«é»‘é©¬äº§å“ï¼Œä¸åŒ…å«è‘—åäº§å“
SAMPLE_PRODUCTS = [
    {
        '_id': '1',
        'name': 'Lovable',
        'description': 'æ¬§æ´²æœ€å¿«å¢é•¿çš„ AI äº§å“ï¼Œ8 ä¸ªæœˆä» 0 åˆ°ç‹¬è§’å…½ã€‚éå¼€å‘è€…ä¹Ÿèƒ½å¿«é€Ÿæ„å»ºå…¨æ ˆåº”ç”¨ã€‚',
        'logo_url': 'https://lovable.dev/favicon.ico',
        'website': 'https://lovable.dev',
        'categories': ['coding'],
        'rating': 4.8,
        'weekly_users': 120000,
        'trending_score': 92,
        'final_score': 92,
        'is_hardware': False,
        'why_matters': 'è¯æ˜äº† AI åŸç”Ÿäº§å“å¯ä»¥æé€Ÿè·å®¢ï¼Œå¯¹æƒ³åš AI åˆ›ä¸šçš„ PM æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚',
        'source': 'sample'
    },
    {
        '_id': '2',
        'name': 'Devin',
        'description': 'å…¨è‡ªä¸» AI è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œèƒ½å¤Ÿç«¯åˆ°ç«¯å¤„ç†éœ€æ±‚æ‹†è§£ã€ä»£ç å®ç°ä¸äº¤ä»˜ã€‚Cognition Labs å‡ºå“ã€‚',
        'logo_url': 'https://cognition.ai/favicon.ico',
        'website': 'https://cognition.ai',
        'categories': ['coding'],
        'rating': 4.7,
        'weekly_users': 160000,
        'trending_score': 93,
        'final_score': 93,
        'is_hardware': False,
        'why_matters': 'é‡æ–°å®šä¹‰äº†ã€ŒAI å·¥ç¨‹å¸ˆã€è¾¹ç•Œï¼ŒPM éœ€è¦æ€è€ƒå¦‚ä½•ä¸ AI åä½œè€Œéä»…ä»…ä½¿ç”¨ AIã€‚',
        'source': 'sample'
    },
    {
        '_id': '3',
        'name': 'Kiro',
        'description': 'AWS èƒŒæ™¯å›¢é˜Ÿæ‰“é€ çš„è§„èŒƒé©±åŠ¨ AI å¼€å‘å¹³å°ï¼Œå¼ºè°ƒç¨³å®šçš„å·¥ç¨‹åŒ–äº¤ä»˜è€Œéç‚«æŠ€ã€‚',
        'logo_url': 'https://kiro.dev/favicon.ico',
        'website': 'https://kiro.dev',
        'categories': ['coding'],
        'rating': 4.7,
        'weekly_users': 85000,
        'trending_score': 90,
        'final_score': 90,
        'is_hardware': False,
        'why_matters': 'å¤§å‚èƒŒæ™¯åˆ›ä¸šï¼Œä¸“æ³¨ä¼ä¸šçº§å¯é æ€§ï¼Œæ˜¯ AI ç¼–ç¨‹å·¥å…·çš„å·®å¼‚åŒ–æ–¹å‘ã€‚',
        'source': 'sample'
    },
    {
        '_id': '4',
        'name': 'Emergent',
        'description': 'éå¼€å‘è€…ä¹Ÿèƒ½ç”¨ AI ä»£ç†æ„å»ºå…¨æ ˆåº”ç”¨çš„å»ºç«™äº§å“ï¼Œé™ä½æŠ€æœ¯é—¨æ§›ã€‚',
        'logo_url': 'https://emergent.sh/favicon.ico',
        'website': 'https://emergent.sh',
        'categories': ['coding'],
        'rating': 4.6,
        'weekly_users': 45000,
        'trending_score': 88,
        'final_score': 88,
        'is_hardware': False,
        'why_matters': 'é¢å‘éæŠ€æœ¯ç”¨æˆ·çš„ AI å¼€å‘å·¥å…·ï¼Œæ‰©å±•äº†ã€Œè°èƒ½åšäº§å“ã€çš„è¾¹ç•Œã€‚',
        'source': 'sample'
    },
    {
        '_id': '5',
        'name': 'Bolt.new',
        'description': 'StackBlitz æ¨å‡ºçš„æµè§ˆå™¨å†…å…¨æ ˆ AI å¼€å‘ç¯å¢ƒï¼Œæ— éœ€é…ç½®å³å¯å¼€å§‹ç¼–ç ã€‚',
        'logo_url': 'https://bolt.new/favicon.ico',
        'website': 'https://bolt.new',
        'categories': ['coding'],
        'rating': 4.8,
        'weekly_users': 200000,
        'trending_score': 91,
        'final_score': 91,
        'is_hardware': False,
        'why_matters': 'é›¶é…ç½® + æµè§ˆå™¨å†…è¿è¡Œï¼Œå¤§å¹…é™ä½ AI å¼€å‘å…¥é—¨é—¨æ§›ã€‚',
        'source': 'sample'
    },
    {
        '_id': '6',
        'name': 'Windsurf',
        'description': 'Codeium æ¨å‡ºçš„ Agentic IDEï¼Œå¼ºè°ƒ AI ä»£ç†ä¸»åŠ¨å‚ä¸å¼€å‘æµç¨‹ã€‚',
        'logo_url': 'https://codeium.com/favicon.ico',
        'website': 'https://codeium.com/windsurf',
        'categories': ['coding'],
        'rating': 4.6,
        'weekly_users': 95000,
        'trending_score': 87,
        'final_score': 87,
        'is_hardware': False,
        'why_matters': 'Agentic IDE æ¦‚å¿µçš„å…ˆè¡Œè€…ï¼Œä»£è¡¨äº† AI ç¼–ç¨‹å·¥å…·çš„æ¼”è¿›æ–¹å‘ã€‚',
        'source': 'sample'
    },
    {
        '_id': '7',
        'name': 'NEO (1X Technologies)',
        'description': 'æŒªå¨åˆåˆ›å…¬å¸ç ”å‘çš„äººå½¢æœºå™¨äººï¼Œå®šä½å®¶åº­åŠ©æ‰‹å’Œè½»å·¥ä¸šåœºæ™¯ã€‚',
        'logo_url': 'https://1x.tech/favicon.ico',
        'website': 'https://1x.tech',
        'categories': ['hardware'],
        'rating': 4.5,
        'weekly_users': 15000,
        'trending_score': 85,
        'final_score': 85,
        'is_hardware': True,
        'why_matters': 'äººå½¢æœºå™¨äººèµ›é“çš„é»‘é©¬ï¼Œèèµ„åä¼°å€¼é£™å‡ï¼Œå€¼å¾—å…³æ³¨å…·èº«æ™ºèƒ½è¶‹åŠ¿ã€‚',
        'source': 'sample'
    },
    {
        '_id': '8',
        'name': 'Rokid AR Studio',
        'description': 'ä¸­å›½ AR çœ¼é•œå‚å•†æ¨å‡ºçš„ AI å¼€å‘å¹³å°ï¼Œæ”¯æŒç©ºé—´è®¡ç®—åº”ç”¨å¼€å‘ã€‚',
        'logo_url': 'https://www.rokid.com/favicon.ico',
        'website': 'https://www.rokid.com',
        'categories': ['hardware'],
        'rating': 4.4,
        'weekly_users': 25000,
        'trending_score': 82,
        'final_score': 82,
        'is_hardware': True,
        'why_matters': 'å›½äº§ AR çœ¼é•œ + AI å¹³å°ï¼Œç©ºé—´è®¡ç®—èµ›é“çš„æœ¬åœŸç©å®¶ã€‚',
        'source': 'sample'
    },
    {
        '_id': '9',
        'name': 'DeepSeek',
        'description': 'ä¸­å›½ AI ç ”ç©¶å…¬å¸ï¼Œä»¥é«˜æ•ˆå¼€æºæ¨¡å‹è‘—ç§°ï¼Œæ€§ä»·æ¯”æé«˜ã€‚',
        'logo_url': 'https://www.deepseek.com/favicon.ico',
        'website': 'https://www.deepseek.com',
        'categories': ['coding', 'writing'],
        'rating': 4.6,
        'weekly_users': 180000,
        'trending_score': 89,
        'final_score': 89,
        'is_hardware': False,
        'why_matters': 'å¼€æºå¤§æ¨¡å‹çš„æ€§ä»·æ¯”ä¹‹ç‹ï¼Œè®­ç»ƒæˆæœ¬ä»…ä¸ºç«å“çš„ 1/10ã€‚',
        'source': 'sample'
    },
    {
        '_id': '10',
        'name': 'Replit Agent',
        'description': 'Replit æ¨å‡ºçš„ AI ä»£ç†ï¼Œèƒ½è‡ªä¸»å®Œæˆä»éœ€æ±‚åˆ°éƒ¨ç½²çš„å®Œæ•´å¼€å‘æµç¨‹ã€‚',
        'logo_url': 'https://replit.com/favicon.ico',
        'website': 'https://replit.com',
        'categories': ['coding'],
        'rating': 4.5,
        'weekly_users': 150000,
        'trending_score': 86,
        'final_score': 86,
        'is_hardware': False,
        'why_matters': 'å…¨æµç¨‹ AI å¼€å‘ä»£ç†ï¼Œä» idea åˆ°ä¸Šçº¿ä¸€ç«™å¼å®Œæˆã€‚',
        'source': 'sample'
    },
    {
        '_id': '11',
        'name': 'Thinking Machines Lab',
        'description': 'è²å¾‹å®¾ AI ç ”ç©¶åˆåˆ›ï¼Œä¸“æ³¨ä¸œå—äºšæœ¬åœ°åŒ–å¤§è¯­è¨€æ¨¡å‹ç ”å‘ã€‚',
        'logo_url': 'https://thinkingmachines.ph/favicon.ico',
        'website': 'https://thinkingmachines.ph',
        'categories': ['other'],
        'rating': 4.3,
        'weekly_users': 12000,
        'trending_score': 78,
        'final_score': 78,
        'is_hardware': False,
        'why_matters': 'ä¸œå—äºšæœ¬åœŸ AI ç ”ç©¶åŠ›é‡ï¼ŒåŒºåŸŸåŒ– AI çš„ä»£è¡¨æ¡ˆä¾‹ã€‚',
        'source': 'sample'
    },
    {
        '_id': '12',
        'name': 'Poe',
        'description': 'Quora æ¨å‡ºçš„å¤šæ¨¡å‹ AI èŠå¤©å¹³å°ï¼Œä¸€ç«™å¼è®¿é—®å¤šç§ AI æ¨¡å‹ã€‚',
        'logo_url': 'https://poe.com/favicon.ico',
        'website': 'https://poe.com',
        'categories': ['other'],
        'rating': 4.5,
        'weekly_users': 280000,
        'trending_score': 84,
        'final_score': 84,
        'is_hardware': False,
        'why_matters': 'AI æ¨¡å‹èšåˆå¹³å°ï¼Œè®©ç”¨æˆ·æ— éœ€åˆ‡æ¢å³å¯å¯¹æ¯”ä¸åŒæ¨¡å‹èƒ½åŠ›ã€‚',
        'source': 'sample'
    },
    {
        '_id': '13',
        'name': 'v0.dev',
        'description': 'Vercel æ¨å‡ºçš„ AI UI ç”Ÿæˆå™¨ï¼Œé€šè¿‡å¯¹è¯ç”Ÿæˆ React ç»„ä»¶ä»£ç ã€‚',
        'logo_url': 'https://v0.dev/favicon.ico',
        'website': 'https://v0.dev',
        'categories': ['coding', 'image'],
        'rating': 4.7,
        'weekly_users': 175000,
        'trending_score': 90,
        'final_score': 90,
        'is_hardware': False,
        'why_matters': 'å‰ç«¯ AI ç”Ÿæˆçš„æ ‡æ†äº§å“ï¼Œè®¾è®¡å¸ˆå’Œå¼€å‘è€…éƒ½èƒ½ç”¨ã€‚',
        'source': 'sample'
    },
    {
        '_id': '14',
        'name': 'Kling AI',
        'description': 'å¿«æ‰‹æ¨å‡ºçš„ AI è§†é¢‘ç”Ÿæˆå·¥å…·ï¼Œæ”¯æŒæ–‡æœ¬/å›¾ç‰‡è½¬è§†é¢‘ã€‚',
        'logo_url': 'https://klingai.com/favicon.ico',
        'website': 'https://klingai.com',
        'categories': ['video'],
        'rating': 4.4,
        'weekly_users': 320000,
        'trending_score': 85,
        'final_score': 85,
        'is_hardware': False,
        'why_matters': 'å›½äº§è§†é¢‘ç”Ÿæˆ AI çš„ä»£è¡¨ï¼Œåœ¨ç‰¹å®šåœºæ™¯ä¸‹æ•ˆæœä¸è¾“æµ·å¤–ç«å“ã€‚',
        'source': 'sample'
    },
    {
        '_id': '15',
        'name': 'Glif',
        'description': 'å¯è§†åŒ– AI å·¥ä½œæµæ„å»ºå¹³å°ï¼Œæ— éœ€ä»£ç å³å¯ä¸²è”å¤šä¸ª AI æ¨¡å‹ã€‚',
        'logo_url': 'https://glif.app/favicon.ico',
        'website': 'https://glif.app',
        'categories': ['image', 'other'],
        'rating': 4.5,
        'weekly_users': 45000,
        'trending_score': 83,
        'final_score': 83,
        'is_hardware': False,
        'why_matters': 'AI å·¥ä½œæµçš„ä¹é«˜ç§¯æœ¨ï¼Œè®©åˆ›æ„äººå£«æ— éœ€å†™ä»£ç ä¹Ÿèƒ½ç©è½¬ AIã€‚',
        'source': 'sample'
    },
]


class ProductRepository:
    """äº§å“æ•°æ®ä»“åº“ç±» - ç®¡ç†æ•°æ®åŠ è½½å’Œç¼“å­˜"""

    _cached_products = None
    _cache_time = None
    _cache_duration = 300  # 5åˆ†é’Ÿç¼“å­˜
    _cached_blogs = None
    _blogs_cache_time = None
    _blogs_cache_duration = BLOG_CACHE_SECONDS

    @classmethod
    def refresh_cache(cls):
        """å¼ºåˆ¶åˆ·æ–°ç¼“å­˜"""
        cls._cached_products = None
        cls._cache_time = None
        cls._cached_blogs = None
        cls._blogs_cache_time = None

    @classmethod
    def load_products(cls, filters_module=None) -> List[Dict]:
        """åŠ è½½äº§å“æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰ã€‚

        ä¼˜å…ˆçº§:
        1) è‹¥è®¾ç½®äº† MONGO_URIï¼Œä¼˜å…ˆè¯»å– MongoDBï¼ˆé€‚é… Vercelï¼‰ã€‚
        2) è‹¥ MongoDB ä¸å¯ç”¨æˆ–ä¸ºç©ºï¼Œåˆ™å›é€€åˆ°æœ¬åœ° JSON é€»è¾‘ã€‚
        """
        now = datetime.now()

        # æ£€æŸ¥ç¼“å­˜
        if cls._cached_products and cls._cache_time:
            age = (now - cls._cache_time).total_seconds()
            if age < cls._cache_duration:
                return cls._cached_products

        products: List[Dict] = []

        # 1) MongoDB path when configured
        if _mongo_uri_configured():
            products = cls.load_from_mongodb()

        # 2) JSON fallback path
        if not products:
            products = cls._load_from_crawler_file()
            if not products:
                products = SAMPLE_PRODUCTS.copy()
            curated = cls._load_curated_dark_horses()
            products = cls._merge_curated_products(products, curated, filters_module)

        # 4. ç»Ÿä¸€å­—æ®µ & è¿‡æ»¤
        if filters_module:
            products = filters_module.normalize_products(products)

        # 5. å»é‡åˆå¹¶ï¼ˆé¿å…é‡å¤å±•ç¤ºï¼‰
        products = cls._dedupe_products(products, filters_module)

        # æ›´æ–°ç¼“å­˜
        cls._cached_products = products
        cls._cache_time = now

        return products

    @classmethod
    def _load_from_crawler_file(cls) -> List[Dict]:
        """ä»ç­–å±•äº§å“æ–‡ä»¶åŠ è½½ (products_featured.json)

        è¿™æ˜¯å”¯ä¸€çš„äº§å“æ•°æ®æºï¼ŒåŒ…å«äººå·¥å®¡æ ¸çš„é«˜è´¨é‡äº§å“ã€‚
        ä¸ä¼šåŠ è½½çˆ¬è™«çš„åŸå§‹è¾“å‡º (products_latest.json)ã€‚
        """
        # åªåŠ è½½ç­–å±•äº§å“æ–‡ä»¶
        if not os.path.exists(PRODUCTS_FEATURED_FILE):
            print("  âš  products_featured.json ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨ç¤ºä¾‹æ•°æ®")
            return []

        try:
            with open(PRODUCTS_FEATURED_FILE, 'r', encoding='utf-8') as f:
                products = json.load(f)

            # æ·»åŠ  _id å­—æ®µ
            for i, p in enumerate(products):
                if '_id' not in p:
                    p['_id'] = str(i + 1)
                if 'extra' in p and isinstance(p['extra'], str):
                    try:
                        p['extra'] = json.loads(p['extra'])
                    except Exception:
                        pass
                if 'community_verdict' in p and isinstance(p['community_verdict'], str):
                    try:
                        p['community_verdict'] = json.loads(p['community_verdict'])
                    except Exception:
                        pass

            print(f"  âœ“ åŠ è½½ {len(products)} ä¸ªç­–å±•äº§å“")
            return products
        except Exception as e:
            print(f"  âš  åŠ è½½ç­–å±•äº§å“å¤±è´¥: {e}")
            return []

    @classmethod
    def _load_curated_dark_horses(cls) -> List[Dict[str, Any]]:
        """Load manually curated dark-horse products."""
        if not os.path.isdir(DARK_HORSES_DIR):
            return []

        curated: List[Dict[str, Any]] = []
        for filename in sorted(os.listdir(DARK_HORSES_DIR)):
            if not filename.endswith('.json'):
                continue
            if filename == 'template.json':
                continue
            path = os.path.join(DARK_HORSES_DIR, filename)
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                if isinstance(data, dict):
                    data = [data]
                if isinstance(data, list):
                    curated.extend(item for item in data if isinstance(item, dict))
            except Exception:
                continue
        return curated

    @classmethod
    def _merge_curated_products(cls, products: List[Dict[str, Any]],
                                curated: List[Dict[str, Any]],
                                filters_module=None) -> List[Dict[str, Any]]:
        """Merge curated products into base list (prefer curated fields)."""
        if not curated:
            return products

        def _key(p: Dict[str, Any]) -> str:
            if filters_module and hasattr(filters_module, 'build_product_key'):
                return filters_module.build_product_key(p)
            return cls._build_product_key(p)

        by_key = {_key(p): p for p in products if p}
        for item in curated:
            normalized = cls._normalize_curated_product(item)
            if not normalized:
                continue
            if filters_module and filters_module.is_blocked(normalized):
                continue
            key = _key(normalized)
            if not key:
                continue
            if key in by_key:
                target = by_key[key]
                for field, value in normalized.items():
                    if value not in (None, '', [], {}):
                        target[field] = value
                continue
            products.append(normalized)
            by_key[key] = normalized
        return products

    @staticmethod
    def _build_product_key(product: Dict[str, Any]) -> str:
        """Normalize a product key for dedupe/merge."""
        website = (product.get('website') or '').strip().lower()
        if website:
            # Normalize scheme/www/port and keep first path segment when available
            try:
                if not website.startswith(('http://', 'https://')) and '.' in website:
                    website = f"https://{website}"
                from urllib.parse import urlparse
                parsed = urlparse(website)
                domain = (parsed.netloc or '').lower()
                if domain.startswith('www.'):
                    domain = domain[4:]
                domain = domain.split(':')[0]
                path = (parsed.path or '').strip('/')
                if path:
                    first = path.split('/')[0]
                    if len(first) > 1:
                        return f"{domain}/{first}"
                return domain
            except Exception:
                return website
        name_key = (product.get('name') or '').strip().lower()
        return ''.join(ch for ch in name_key if ch.isalnum())

    @classmethod
    def _merge_product_fields(cls, target: Dict[str, Any], source: Dict[str, Any]) -> None:
        """Merge source fields into target with simple quality heuristics."""
        if not source:
            return

        numeric_max_fields = {'dark_horse_index', 'final_score', 'hot_score', 'trending_score', 'rating'}
        date_fields = {'discovered_at', 'first_seen', 'published_at', 'news_updated_at'}
        country_fields = {'region', 'country_code', 'country_name', 'country_flag', 'country_display', 'country_source'}
        country_source_priority = {
            'unknown': 0,
            # Keep old region-based fallbacks at the lowest rank so better evidence can replace them.
            'region:search_fallback': -1,
            'region:fallback': -1,
            'website:cc_tld': 1,
            'region:legacy': 2,
            'curated:region': 3,
        }

        def _is_unknown_country(field: str, value: Any) -> bool:
            text = str(value or '').strip().lower()
            if field == 'country_code':
                return text in {'', 'unknown'}
            if field == 'country_flag':
                return text in {'', 'ğŸŒ'}
            if field == 'region':
                return text in {'', 'unknown', 'ğŸŒ'}
            return text in {'', 'unknown', 'n/a', 'na', 'none', 'null'}

        for field, value in source.items():
            if value in (None, '', [], {}):
                continue

            if field in country_fields:
                current = target.get(field)
                if field == 'country_source':
                    current_rank = country_source_priority.get(str(current or '').strip().lower(), 4)
                    value_rank = country_source_priority.get(str(value or '').strip().lower(), 4)
                    if value_rank >= current_rank:
                        target[field] = value
                    continue
                if _is_unknown_country(field, current) and not _is_unknown_country(field, value):
                    target[field] = value
                    continue
                if not current:
                    target[field] = value
                continue

            if field in numeric_max_fields:
                try:
                    current = target.get(field) or 0
                    target[field] = max(float(current), float(value))
                except Exception:
                    if not target.get(field):
                        target[field] = value
                continue

            if field == 'funding_total':
                try:
                    current = target.get(field) or ''
                    if sorting.parse_funding(value) > sorting.parse_funding(current):
                        target[field] = value
                except Exception:
                    if not target.get(field):
                        target[field] = value
                continue

            if field in date_fields:
                try:
                    current = target.get(field)
                    current_dt = sorting.parse_date(current)
                    value_dt = sorting.parse_date(value)
                    if value_dt and (not current_dt or value_dt > current_dt):
                        target[field] = value
                except Exception:
                    if not target.get(field):
                        target[field] = value
                continue

            # Prefer longer/denser text for narrative fields
            if field in {'description', 'why_matters', 'latest_news'}:
                current = str(target.get(field) or '')
                candidate = str(value)
                if len(candidate) > len(current):
                    target[field] = value
                continue

            # Default: fill missing fields
            if not target.get(field):
                target[field] = value

    @classmethod
    def _dedupe_products(cls, products: List[Dict[str, Any]],
                         filters_module=None) -> List[Dict[str, Any]]:
        """Deduplicate products by normalized key, merging fields."""
        if not products:
            return []

        def _key(p: Dict[str, Any]) -> str:
            if filters_module and hasattr(filters_module, 'build_product_key'):
                return filters_module.build_product_key(p)
            return cls._build_product_key(p)

        def _name_key(p: Dict[str, Any]) -> str:
            raw_name = (p.get('name') or '').strip()
            if not raw_name:
                return ''
            # If name contains non-ASCII, only dedupe on exact normalized name
            if any(ord(ch) > 127 for ch in raw_name):
                normalized = ''.join(raw_name.lower().split())
                return normalized if len(normalized) >= 2 else ''

            # ASCII name: normalize punctuation and require a minimum length
            import re as _re
            key = _re.sub(r'[^a-z0-9]+', '', raw_name.lower())
            if len(key) < 4:
                return ''
            if not _re.search(r'[a-z0-9]', key):
                return ''
            return key

        def _name_key_loose(p: Dict[str, Any]) -> str:
            """Looser name key for near-duplicate variants like '* Smart Glasses'."""
            raw_name = (p.get('name') or '').strip()
            if not raw_name:
                return ''
            if any(ord(ch) > 127 for ch in raw_name):
                return ''

            import re as _re
            tokens = _re.findall(r'[a-z0-9]+', raw_name.lower())
            if not tokens:
                return ''

            stopwords = {
                'ai', 'smart', 'intelligent', 'android', 'xr', 'ar', 'vr',
                'glass', 'glasses', 'device', 'wearable', 'edition', 'version',
                'model', 'pro', 'plus', 'ultra', 'new', 'first',
            }
            core = [t for t in tokens if t not in stopwords and len(t) > 1]
            if len(core) < 2:
                return ''
            return ''.join(core[:4])

        by_key: Dict[str, Dict[str, Any]] = {}
        by_name: Dict[str, Dict[str, Any]] = {}
        by_name_loose: Dict[str, Dict[str, Any]] = {}
        ordered: List[Dict[str, Any]] = []

        for product in products:
            if not isinstance(product, dict):
                continue
            key = _key(product)
            name_key = _name_key(product)
            name_key_loose = _name_key_loose(product)

            if key and key in by_key:
                cls._merge_product_fields(by_key[key], product)
                continue

            if name_key and name_key in by_name:
                target = by_name[name_key]
                cls._merge_product_fields(target, product)
                if key:
                    by_key[key] = target
                continue

            if name_key_loose and name_key_loose in by_name_loose:
                target = by_name_loose[name_key_loose]
                cls._merge_product_fields(target, product)
                if key:
                    by_key[key] = target
                if name_key:
                    by_name[name_key] = target
                continue

            if key:
                by_key[key] = product
            if name_key:
                by_name[name_key] = product
            if name_key_loose:
                by_name_loose[name_key_loose] = product
            ordered.append(product)

        # Re-assign _id to keep uniqueness after dedupe
        for i, p in enumerate(ordered):
            p['_id'] = str(i + 1)

        return ordered

    @staticmethod
    def _normalize_curated_product(product: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Map curated dark-horse fields into standard product fields."""
        if not isinstance(product, dict):
            return None
        normalized = product.copy()
        if not normalized.get('logo_url'):
            normalized['logo_url'] = normalized.get('logo') or normalized.get('logoUrl') or ''
        if not normalized.get('categories'):
            category = normalized.get('category')
            if category:
                normalized['categories'] = [category]
        if not normalized.get('source'):
            normalized['source'] = 'curated'
        if 'is_hardware' not in normalized:
            normalized['is_hardware'] = False
        return normalized

    @classmethod
    def load_from_mongodb(cls) -> List[Dict]:
        """ä»MongoDBåŠ è½½äº§å“æ•°æ®"""
        from .product_filters import BLOCKED_SOURCES

        db = get_mongo_db()
        if db is None:
            return []

        try:
            collection = db.products
            blocked_sources = list(BLOCKED_SOURCES)
            # è·å–äº§å“ï¼Œæ’é™¤ content_type='blog' å’Œ content_type='filtered'
            products = list(collection.find(
                {
                    'content_type': {'$nin': ['blog', 'filtered']},
                    'source': {'$nin': blocked_sources}
                },
                {'_id': 0}
            ).sort('final_score', -1))

            # å¦‚æœæ²¡æœ‰ content_type å­—æ®µï¼Œè·å–æ‰€æœ‰äº§å“
            if not products:
                products = list(collection.find(
                    {'source': {'$nin': blocked_sources}},
                    {'_id': 0}
                ).sort('final_score', -1))

            if products:
                print(f"  âœ“ Loaded {len(products)} products from MongoDB")

            # æ·»åŠ  _id å­—æ®µ
            for i, p in enumerate(products):
                if '_id' not in p:
                    p['_id'] = str(i + 1)
                # Parse extra field if it's a string
                if 'extra' in p and isinstance(p['extra'], str):
                    try:
                        p['extra'] = json.loads(p['extra'])
                    except:
                        pass
                if 'community_verdict' in p and isinstance(p['community_verdict'], str):
                    try:
                        p['community_verdict'] = json.loads(p['community_verdict'])
                    except Exception:
                        pass

            return products
        except Exception as e:
            print(f"  âš  MongoDB load failed: {e}")
            return []

    @classmethod
    def load_blogs(cls) -> List[Dict]:
        """åŠ è½½åšå®¢/æ–°é—»/è®¨è®ºæ•°æ®ï¼ˆä¼˜å…ˆ MongoDBï¼Œå›é€€ JSONï¼‰ã€‚"""
        now = datetime.now()

        # æ£€æŸ¥ç¼“å­˜
        if cls._cached_blogs is not None and cls._blogs_cache_time:
            age = (now - cls._blogs_cache_time).total_seconds()
            if age < cls._blogs_cache_duration:
                return cls._cached_blogs

        blogs: List[Dict] = []

        if _mongo_uri_configured():
            blogs = cls.load_blogs_from_mongodb()

        if not blogs:
            if not os.path.exists(BLOGS_NEWS_FILE):
                cls._cached_blogs = []
                cls._blogs_cache_time = now
                return []

            try:
                with open(BLOGS_NEWS_FILE, 'r', encoding='utf-8') as f:
                    blogs = json.load(f)

                # æ·»åŠ  _id å­—æ®µ
                for i, b in enumerate(blogs):
                    if '_id' not in b:
                        b['_id'] = f"blog_{i + 1}"
            except Exception as e:
                print(f"åŠ è½½åšå®¢æ•°æ®å¤±è´¥: {e}")
                blogs = []

        cls._cached_blogs = blogs
        cls._blogs_cache_time = now
        return blogs

    @classmethod
    def load_blogs_from_mongodb(cls) -> List[Dict]:
        """ä» MongoDB åŠ è½½åšå®¢æ•°æ®ã€‚"""
        db = get_mongo_db()
        if db is None:
            return []

        try:
            collection = db.blogs
            blogs = list(collection.find({}, {'_id': 0}).sort('published_at', -1))
            if not blogs:
                blogs = list(collection.find({}, {'_id': 0}).sort('created_at', -1))

            for i, b in enumerate(blogs):
                if '_id' not in b:
                    b['_id'] = f"blog_{i + 1}"
            return blogs
        except Exception as e:
            print(f"  âš  MongoDB blog load failed: {e}")
            return []

    @staticmethod
    def get_last_updated() -> Dict[str, Any]:
        """è·å–æœ€è¿‘ä¸€æ¬¡æ•°æ®æ›´æ–°æ—¶é—´."""
        if not os.path.exists(LAST_UPDATED_FILE):
            return {'last_updated': None, 'hours_ago': None}

        try:
            with open(LAST_UPDATED_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except Exception:
            return {'last_updated': None, 'hours_ago': None}

        last_updated = data.get('last_updated')
        if not last_updated:
            return {'last_updated': None, 'hours_ago': None}

        try:
            parsed = datetime.fromisoformat(str(last_updated).replace('Z', '+00:00'))
            hours_ago = round((datetime.now(parsed.tzinfo) - parsed).total_seconds() / 3600, 1)
        except Exception:
            hours_ago = None

        return {'last_updated': last_updated, 'hours_ago': hours_ago}

    @staticmethod
    def load_industry_leaders() -> Dict:
        """è·å–è¡Œä¸šé¢†å†›äº§å“ - å·²çŸ¥åçš„æˆç†Ÿ AI äº§å“å‚è€ƒåˆ—è¡¨"""
        industry_leaders_file = os.path.join(CRAWLER_DATA_DIR, 'industry_leaders.json')

        if os.path.exists(industry_leaders_file):
            try:
                with open(industry_leaders_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"Error loading industry leaders: {e}")
                return {"categories": {}}

        return {"categories": {}}
